{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load data:"
      ],
      "metadata": {
        "id": "HveAfLU7ES5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_OYCuToZshd"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "(train_ds, test_ds), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data:"
      ],
      "metadata": {
        "id": "uyVjzc2SLOED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_mnist_data(mnist):\n",
        "  # change values from uint8 to float32\n",
        "  mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
        "  # reshape image from 3D (28,28,1) to 1D (256,)\n",
        "  mnist = mnist.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
        "  # normalize the vectors (from 0 - 255 to -1 - 1)\n",
        "  mnist = mnist.map(lambda img, target: (((img/128.)-1.), target))\n",
        "  # create one-hot targets for each handwritten numner (0-9)\n",
        "  mnist = mnist.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
        "  # cache progress\n",
        "  mnist = mnist.cache()\n",
        "  # shuffle, batch, and prefetch data\n",
        "  mnist = mnist.shuffle(1000)\n",
        "  mnist = mnist.batch(32)\n",
        "  mnist = mnist.prefetch(20)\n",
        "  # return preprocessed dataset\n",
        "  return mnist\n",
        "  \n",
        "# apply method to datasets\n",
        "train_dataset = train_ds.apply(prepare_mnist_data)\n",
        "test_dataset = test_ds.apply(prepare_mnist_data)"
      ],
      "metadata": {
        "id": "bR1C1jHHLYtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many training/test images are there? **60,000/10,000**. What's the image shape? **28x28x1**. What range are pixel values in? **0-255**."
      ],
      "metadata": {
        "id": "BmYU9UykVaxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create network:"
      ],
      "metadata": {
        "id": "V-VaGoA-VU8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ToaqOAAOVX9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training loop:"
      ],
      "metadata": {
        "id": "yz7dCQK1AVSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, input, target,loss_function, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # binary attribute: right (1) or wrong (0) prediction?\n",
        "  test_accuracy_aggregator = []\n",
        "  # continuous attribute: how close is the output to the target?\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    # prediction stays unseen to the network (does not update it's weights with respect to it)\n",
        "    prediction = model(input)\n",
        "    # same as in training: callable loss object\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    # is the highest value in our predicted outputs the same one as in our one-hot targets?\n",
        "    sample_test_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    # average over batch size (32) -> get the mean: out of 32, how many were correct?\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    # append test losses\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    # append the mean of the accuracy\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))    \n",
        "\n",
        "  # Now we have a large list of accuracies and losses for all elements in the test data\n",
        "  \n",
        "  # Calculate mean of both loss and accuracy\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "H7_BLmpDAX_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training:"
      ],
      "metadata": {
        "id": "DucX_dP7E7KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#For showcasing we only use a subset of the training and test data (generally use all of the available data!)\n",
        "train_dataset = train_dataset.take(1000)\n",
        "test_dataset = test_dataset.take(100)\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Initialize the model.\n",
        "model = MyModel()\n",
        "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "# Initialize the optimizer: SGD with default parameters. Check out 'tf.keras.optimizers'\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "#testing once before we begin\n",
        "test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
        "train_losses.append(train_loss)\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {str(epoch)} starting with accuracy {test_accuracies[-1]}')\n",
        "\n",
        "    #training (and checking in with training)\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in train_dataset:\n",
        "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        epoch_loss_agg.append(train_loss)\n",
        "    \n",
        "    #track training loss\n",
        "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
        "\n",
        "    #testing, so we can track accuracy and test loss\n",
        "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umuLUFILE6yf",
        "outputId": "aecf6e04-3843-43d8-fd97-cfcbc726750c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 starting with accuracy 0.1\n",
            "Epoch: 1 starting with accuracy 0.05\n",
            "Epoch: 2 starting with accuracy 0.06\n",
            "Epoch: 3 starting with accuracy 0.06\n",
            "Epoch: 4 starting with accuracy 0.09\n",
            "Epoch: 5 starting with accuracy 0.08\n",
            "Epoch: 6 starting with accuracy 0.09\n",
            "Epoch: 7 starting with accuracy 0.08\n",
            "Epoch: 8 starting with accuracy 0.05\n",
            "Epoch: 9 starting with accuracy 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization:"
      ],
      "metadata": {
        "id": "GiY1nx11M9PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualization (train_losses, test_losses,\n",
        "test_accuracies):\n",
        "  plt.figure()\n",
        "  line1, = plt.plot(train_losses, \"b-\")\n",
        "  line2, = plt.plot(test_losses, \"r-\")\n",
        "  line3, = plt.plot(test_accuracies, \"r:\")\n",
        "  plt.xlabel(\" Training steps \")\n",
        "  plt.ylabel (\" Loss / Accuracy \")\n",
        "  plt.legend((line1, line2, line3), (\" training loss \", \" test loss \", \" test accuracy \"))\n",
        "  plt.show()\n",
        "\n",
        "visualization(train_losses, test_losses, test_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "On1m_GNrM_dL",
        "outputId": "e1489307-67ec-4ef0-addd-ba9aac88c03f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Variations:\n",
        "\n",
        "**Learning rate: 0.001 -> 0.1:** faster reduction of test loss and training loss, test loss went up a bit at the end, overall better result\n",
        "\n",
        "**Learning rate = 0.1 X Batch Size: 32 -> 64:** not much has changed, loss doesn't go up, even slightly better result\n",
        "\n",
        "**Learning rate = 0.1 X Batch Size = 1:** training loss and test loss do not get better, even higher, accuracy stays very low\n",
        "\n",
        "**Learning rate = 0.1 X Batch Size = 64 X tf.keras.layers.Dense(units=256) -> 128:** very similar, except more volatile at the end, probably disadvantageous because of the inconsistency\n",
        "\n",
        "**Learning rate = 0.1 X Batch Size = 64 X tf.keras.layers.Dense(units=256) -> 32:** very volatile, worse result, wouldn't recommend\n",
        "\n",
        "**Learning rate = 0.1 X Batch Size = 32 X tf.keras.layers.Dense(units=256, activation.nn.relu) -> tf.math.sigmoid:** comparable result to ReLU\n",
        "\n",
        "\n",
        "\n",
        "**Learning rate:** Up to a certain point, higher learning rates cause steeper declines in test and training loss. On the other side, there are more fluctations, as there is a higher risk of moving too far in the (negative) gradient direction. If the learning is too high (1 is already way too high), the network constantly overshoots in its gradient descents and does not considerably increase its accuracy during 10 epochs. The loss stays high and the accuracy low.\n",
        "\n",
        "**Available data:** The network takes way longer to train if we use all the available data and not only take 1000 training examples and 100 test examples. Why is this affecting the speed so much? Because we have to iterate through all 60,000 training and 10,000 test samples\n",
        "\n",
        "**See variation of plots here:** https://docs.google.com/document/d/1dlKWkrKuIfBjq-F9nI-VczJ88EwWX_4OhiSHYPZTIco/edit?usp=sharing"
      ],
      "metadata": {
        "id": "cRema7M5RC6R"
      }
    }
  ]
}